{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":31234,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T09:31:37.500861Z","iopub.execute_input":"2026-01-02T09:31:37.501238Z","iopub.status.idle":"2026-01-02T09:31:37.506340Z","shell.execute_reply.started":"2026-01-02T09:31:37.501210Z","shell.execute_reply":"2026-01-02T09:31:37.505178Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\n\ndata = np.array(data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T09:31:37.509749Z","iopub.execute_input":"2026-01-02T09:31:37.510457Z","iopub.status.idle":"2026-01-02T09:31:40.762224Z","shell.execute_reply.started":"2026-01-02T09:31:37.510421Z","shell.execute_reply":"2026-01-02T09:31:40.760879Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"m , n =data.shape \n\nm,n\n\ndata_train = data[0:m].T\nx = data_train[ 1 :n ]\nx = x/225\n\ny = data_train [0]\n\n\nx_train = x[ : , : 38000]\ny_train = y[:38000]\n\nx_test = x[ : , 38000:]\ny_test = y[38000:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T09:31:40.764243Z","iopub.execute_input":"2026-01-02T09:31:40.764998Z","iopub.status.idle":"2026-01-02T09:31:40.880478Z","shell.execute_reply.started":"2026-01-02T09:31:40.764929Z","shell.execute_reply":"2026-01-02T09:31:40.879515Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def init_params ():\n\n    w1 = np.random.rand(128,784) - 0.5\n    b1 = np.random.rand(128,1) - 0.5\n\n    w2 = np.random.rand(64,128) - 0.5\n    b2 = np.random.rand(64,1) - 0.5\n\n    w3 = np.random.rand(32,64) - 0.5\n    b3 = np.random.rand(32,1) - 0.5\n\n    w4 = np.random.rand(10,32) - 0.5\n    b4 = np.random.rand(10,1) - 0.5\n    \n    return w1, b1, w2, b2, w3, b3, w4, b4\n\n\n\ndef Relu(z):\n    return  np.maximum(0,z)\n\ndef soft_max(z):\n    \n    exp_z = np.exp(z - np.max(z, axis=0, keepdims=True))  \n    return exp_z / np.sum(exp_z, axis=0, keepdims=True)\n\n\ndef forward_prop ( w1, b1, w2, b2, w3, b3, w4, b4, x):\n\n    z1 = w1.dot(x)+ b1\n    a1 = Relu(z1)\n\n    z2 = w2.dot(a1)+ b2\n    a2 = Relu(z2)\n\n    z3 = w3.dot(a2)+ b3\n    a3 = Relu(z3)\n\n    z4 = w4.dot(a3)+ b4\n    a4 = soft_max(z4)\n\n    return z1, a1, z2, a2, z3, a3, z4, a4 \n\ndef relu_deriv(z):\n    return (z > 0).astype(float)\n\ndef one_hot(y):\n\n    one_hot_y = np.zeros((y.size , y.max() +1))\n    one_hot_y[np.arange(y.size ) , y] = 1\n    one_hot_y = one_hot_y.T\n\n    return one_hot_y\n\n\ndef back_prop(z1, a1, z2, a2, z3, a3, z4, a4, w4, w3, w2, y, x ):\n\n    m = y.size\n    one_hot_y = one_hot(y)\n\n    dz4 = a4- one_hot_y\n    dw4 = 1/m * dz4.dot(a3.T)\n    db4 = 1/m * np.sum(dz4, axis=1, keepdims = True)\n\n    dz3 = w4.T.dot(dz4) * relu_deriv(z3)\n    dw3 = 1/m * dz3.dot(a2.T)\n    db3 = 1/m * np.sum ( dz3, axis = 1, keepdims = True)\n\n    dz2 =  w3.T.dot(dz3) * relu_deriv(z2)\n    dw2 = 1/m * dz2.dot(a1.T)\n    db2 = 1/m * np.sum ( dz2, axis = 1, keepdims = True)\n\n    dz1 =  w2.T.dot(dz2)  * relu_deriv(z1)\n    dw1 = 1/m * dz1.dot(x.T)\n    db1 = 1/m * np.sum(dz1, axis = 1, keepdims = True)\n\n    return (dw1, db1, dw2, db2, dw3, db3, dw4, db4)\n\ndef update_params(w1, w2, w3, w4, b1, b2, b3, b4, dw1, db1, dw2, db2, dw3, db3, dw4, db4, alpha):\n\n    w1 = w1- alpha*dw1\n    b1 = b1- alpha*db1\n\n    w2 = w2- alpha*dw2\n    b2 = b2- alpha*db2\n\n    w3 = w3- alpha*dw3\n    b3 = b3- alpha*db3\n\n    w4 = w4- alpha*dw4\n    b4 = b4- alpha*db4\n\n    return w1, b1, w2, b2, w3, b3, w4, b4 \n\n\ndef grad_descent( w1, b1, w2, b2, w3, b3, w4, b4, x , y , iterations , alpha):\n    \n\n    for i in range(iterations):\n        z1, a1, z2, a2, z3, a3, z4, a4 = forward_prop(w1, b1, w2, b2, w3, b3, w4, b4, x)\n\n        dw1, db1, dw2, db2, dw3, db3, dw4, db4 = back_prop(\n            z1, a1, z2, a2, z3, a3, z4, a4, w4, w3, w2, y, x\n        )\n\n        w1, b1, w2, b2, w3, b3, w4, b4 = update_params(w1,w2,w3,w4, b1, b2, b3, b4,\n            dw1, db1, dw2, db2, dw3, db3, dw4, db4, alpha\n        )\n\n        if i % 10 == 0:\n            train_preds = np.argmax(a4, axis=0)   # <-- SHOULD BE a4, NOT a2\n            train_acc = np.mean(train_preds == y_train) * 100\n            print(\"Iteration:\", i, \"Training Accuracy:\", train_acc, \"%\")\n\n    return w1, b1, w2, b2, w3, b3, w4, b4\n\n\nw1, b1, w2, b2, w3, b3, w4, b4 = init_params()\n\n       \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T10:04:58.776450Z","iopub.execute_input":"2026-01-02T10:04:58.776849Z","iopub.status.idle":"2026-01-02T10:04:58.798549Z","shell.execute_reply.started":"2026-01-02T10:04:58.776815Z","shell.execute_reply":"2026-01-02T10:04:58.797394Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T10:02:36.146299Z","iopub.execute_input":"2026-01-02T10:02:36.146681Z","iopub.status.idle":"2026-01-02T10:02:36.153160Z","shell.execute_reply.started":"2026-01-02T10:02:36.146654Z","shell.execute_reply":"2026-01-02T10:02:36.152029Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"w1, b1, w2, b2, w3, b3, w4, b4 =  grad_descent(w1, b1, w2, b2, w3, b3, w4, b4, x_train, y_train, 1000 , 0.05)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T10:05:17.885709Z","iopub.execute_input":"2026-01-02T10:05:17.886078Z","iopub.status.idle":"2026-01-02T10:16:50.390389Z","shell.execute_reply.started":"2026-01-02T10:05:17.886049Z","shell.execute_reply":"2026-01-02T10:16:50.389269Z"}},"outputs":[{"name":"stdout","text":"Iteration: 0 Training Accuracy: 8.51842105263158 %\nIteration: 10 Training Accuracy: 26.75526315789474 %\nIteration: 20 Training Accuracy: 37.373684210526314 %\nIteration: 30 Training Accuracy: 43.77368421052631 %\nIteration: 40 Training Accuracy: 49.15 %\nIteration: 50 Training Accuracy: 53.85263157894736 %\nIteration: 60 Training Accuracy: 57.46052631578947 %\nIteration: 70 Training Accuracy: 60.6 %\nIteration: 80 Training Accuracy: 63.30263157894736 %\nIteration: 90 Training Accuracy: 65.57105263157895 %\nIteration: 100 Training Accuracy: 67.76578947368421 %\nIteration: 110 Training Accuracy: 69.67368421052632 %\nIteration: 120 Training Accuracy: 71.38947368421053 %\nIteration: 130 Training Accuracy: 73.03684210526316 %\nIteration: 140 Training Accuracy: 74.49736842105264 %\nIteration: 150 Training Accuracy: 75.6342105263158 %\nIteration: 160 Training Accuracy: 76.74736842105263 %\nIteration: 170 Training Accuracy: 77.73684210526316 %\nIteration: 180 Training Accuracy: 78.6236842105263 %\nIteration: 190 Training Accuracy: 79.38684210526316 %\nIteration: 200 Training Accuracy: 80.00263157894737 %\nIteration: 210 Training Accuracy: 80.67894736842105 %\nIteration: 220 Training Accuracy: 81.27105263157894 %\nIteration: 230 Training Accuracy: 81.74736842105264 %\nIteration: 240 Training Accuracy: 82.18947368421053 %\nIteration: 250 Training Accuracy: 82.58947368421052 %\nIteration: 260 Training Accuracy: 82.9421052631579 %\nIteration: 270 Training Accuracy: 83.31052631578947 %\nIteration: 280 Training Accuracy: 83.68157894736842 %\nIteration: 290 Training Accuracy: 83.96052631578948 %\nIteration: 300 Training Accuracy: 84.28157894736842 %\nIteration: 310 Training Accuracy: 84.58684210526316 %\nIteration: 320 Training Accuracy: 84.88157894736842 %\nIteration: 330 Training Accuracy: 85.12105263157895 %\nIteration: 340 Training Accuracy: 85.32894736842105 %\nIteration: 350 Training Accuracy: 85.54473684210527 %\nIteration: 360 Training Accuracy: 85.76315789473684 %\nIteration: 370 Training Accuracy: 85.95789473684209 %\nIteration: 380 Training Accuracy: 86.10263157894737 %\nIteration: 390 Training Accuracy: 86.33684210526316 %\nIteration: 400 Training Accuracy: 86.48947368421052 %\nIteration: 410 Training Accuracy: 86.68421052631578 %\nIteration: 420 Training Accuracy: 86.8 %\nIteration: 430 Training Accuracy: 86.97368421052632 %\nIteration: 440 Training Accuracy: 87.13947368421053 %\nIteration: 450 Training Accuracy: 87.26315789473685 %\nIteration: 460 Training Accuracy: 87.39473684210526 %\nIteration: 470 Training Accuracy: 87.4921052631579 %\nIteration: 480 Training Accuracy: 87.65526315789474 %\nIteration: 490 Training Accuracy: 87.78684210526316 %\nIteration: 500 Training Accuracy: 87.90526315789474 %\nIteration: 510 Training Accuracy: 88.03157894736842 %\nIteration: 520 Training Accuracy: 88.16842105263157 %\nIteration: 530 Training Accuracy: 88.27894736842106 %\nIteration: 540 Training Accuracy: 88.38157894736842 %\nIteration: 550 Training Accuracy: 88.47894736842106 %\nIteration: 560 Training Accuracy: 88.57894736842105 %\nIteration: 570 Training Accuracy: 88.66315789473684 %\nIteration: 580 Training Accuracy: 88.77631578947368 %\nIteration: 590 Training Accuracy: 88.87631578947368 %\nIteration: 600 Training Accuracy: 88.98684210526315 %\nIteration: 610 Training Accuracy: 89.06842105263158 %\nIteration: 620 Training Accuracy: 89.14999999999999 %\nIteration: 630 Training Accuracy: 89.2 %\nIteration: 640 Training Accuracy: 89.29473684210527 %\nIteration: 650 Training Accuracy: 89.37894736842105 %\nIteration: 660 Training Accuracy: 89.47894736842106 %\nIteration: 670 Training Accuracy: 89.54736842105262 %\nIteration: 680 Training Accuracy: 89.61315789473684 %\nIteration: 690 Training Accuracy: 89.69473684210526 %\nIteration: 700 Training Accuracy: 89.77894736842106 %\nIteration: 710 Training Accuracy: 89.87368421052632 %\nIteration: 720 Training Accuracy: 89.97631578947369 %\nIteration: 730 Training Accuracy: 90.0421052631579 %\nIteration: 740 Training Accuracy: 90.10263157894737 %\nIteration: 750 Training Accuracy: 90.16578947368421 %\nIteration: 760 Training Accuracy: 90.20263157894736 %\nIteration: 770 Training Accuracy: 90.26315789473685 %\nIteration: 780 Training Accuracy: 90.32631578947368 %\nIteration: 790 Training Accuracy: 90.36842105263158 %\nIteration: 800 Training Accuracy: 90.42105263157895 %\nIteration: 810 Training Accuracy: 90.46842105263157 %\nIteration: 820 Training Accuracy: 90.50263157894737 %\nIteration: 830 Training Accuracy: 90.54736842105264 %\nIteration: 840 Training Accuracy: 90.60000000000001 %\nIteration: 850 Training Accuracy: 90.6236842105263 %\nIteration: 860 Training Accuracy: 90.68947368421053 %\nIteration: 870 Training Accuracy: 90.75263157894737 %\nIteration: 880 Training Accuracy: 90.79473684210527 %\nIteration: 890 Training Accuracy: 90.82894736842105 %\nIteration: 900 Training Accuracy: 90.87894736842105 %\nIteration: 910 Training Accuracy: 90.91842105263159 %\nIteration: 920 Training Accuracy: 90.97368421052632 %\nIteration: 930 Training Accuracy: 91.02631578947368 %\nIteration: 940 Training Accuracy: 91.0657894736842 %\nIteration: 950 Training Accuracy: 91.12105263157895 %\nIteration: 960 Training Accuracy: 91.15526315789474 %\nIteration: 970 Training Accuracy: 91.18684210526315 %\nIteration: 980 Training Accuracy: 91.23684210526316 %\nIteration: 990 Training Accuracy: 91.27105263157895 %\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"w1, b1, w2, b2, w3, b3, w4, b4 =  grad_descent(w1, b1, w2, b2, w3, b3, w4, b4, x_train, y_train, 500 , 0.01)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T10:16:57.721086Z","iopub.execute_input":"2026-01-02T10:16:57.721429Z","iopub.status.idle":"2026-01-02T10:22:44.156642Z","shell.execute_reply.started":"2026-01-02T10:16:57.721402Z","shell.execute_reply":"2026-01-02T10:22:44.155914Z"}},"outputs":[{"name":"stdout","text":"Iteration: 0 Training Accuracy: 91.30526315789473 %\nIteration: 10 Training Accuracy: 91.30789473684212 %\nIteration: 20 Training Accuracy: 91.31315789473685 %\nIteration: 30 Training Accuracy: 91.32894736842105 %\nIteration: 40 Training Accuracy: 91.33421052631579 %\nIteration: 50 Training Accuracy: 91.34473684210526 %\nIteration: 60 Training Accuracy: 91.35263157894737 %\nIteration: 70 Training Accuracy: 91.36315789473684 %\nIteration: 80 Training Accuracy: 91.37105263157895 %\nIteration: 90 Training Accuracy: 91.37368421052632 %\nIteration: 100 Training Accuracy: 91.38157894736842 %\nIteration: 110 Training Accuracy: 91.38421052631578 %\nIteration: 120 Training Accuracy: 91.39473684210526 %\nIteration: 130 Training Accuracy: 91.40789473684211 %\nIteration: 140 Training Accuracy: 91.41052631578947 %\nIteration: 150 Training Accuracy: 91.43157894736842 %\nIteration: 160 Training Accuracy: 91.43947368421053 %\nIteration: 170 Training Accuracy: 91.45263157894736 %\nIteration: 180 Training Accuracy: 91.45526315789473 %\nIteration: 190 Training Accuracy: 91.46052631578947 %\nIteration: 200 Training Accuracy: 91.47105263157894 %\nIteration: 210 Training Accuracy: 91.47105263157894 %\nIteration: 220 Training Accuracy: 91.47631578947369 %\nIteration: 230 Training Accuracy: 91.47894736842105 %\nIteration: 240 Training Accuracy: 91.48421052631579 %\nIteration: 250 Training Accuracy: 91.50263157894737 %\nIteration: 260 Training Accuracy: 91.5078947368421 %\nIteration: 270 Training Accuracy: 91.51315789473684 %\nIteration: 280 Training Accuracy: 91.51842105263158 %\nIteration: 290 Training Accuracy: 91.52894736842106 %\nIteration: 300 Training Accuracy: 91.53421052631579 %\nIteration: 310 Training Accuracy: 91.54473684210527 %\nIteration: 320 Training Accuracy: 91.54736842105264 %\nIteration: 330 Training Accuracy: 91.5421052631579 %\nIteration: 340 Training Accuracy: 91.56315789473685 %\nIteration: 350 Training Accuracy: 91.57894736842105 %\nIteration: 360 Training Accuracy: 91.58421052631579 %\nIteration: 370 Training Accuracy: 91.59736842105262 %\nIteration: 380 Training Accuracy: 91.60263157894737 %\nIteration: 390 Training Accuracy: 91.61315789473684 %\nIteration: 400 Training Accuracy: 91.61315789473684 %\nIteration: 410 Training Accuracy: 91.6263157894737 %\nIteration: 420 Training Accuracy: 91.63157894736842 %\nIteration: 430 Training Accuracy: 91.64210526315789 %\nIteration: 440 Training Accuracy: 91.65263157894736 %\nIteration: 450 Training Accuracy: 91.65263157894736 %\nIteration: 460 Training Accuracy: 91.66578947368421 %\nIteration: 470 Training Accuracy: 91.67894736842105 %\nIteration: 480 Training Accuracy: 91.6842105263158 %\nIteration: 490 Training Accuracy: 91.69473684210526 %\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"w1, b1, w2, b2, w3, b3, w4, b4 =  grad_descent(w1, b1, w2, b2, w3, b3, w4, b4, x_train, y_train, 500 , 0.05\n                                              )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T10:24:14.460827Z","iopub.execute_input":"2026-01-02T10:24:14.461213Z","iopub.status.idle":"2026-01-02T10:29:53.933258Z","shell.execute_reply.started":"2026-01-02T10:24:14.461184Z","shell.execute_reply":"2026-01-02T10:29:53.932339Z"}},"outputs":[{"name":"stdout","text":"Iteration: 0 Training Accuracy: 91.70526315789473 %\nIteration: 10 Training Accuracy: 91.75263157894736 %\nIteration: 20 Training Accuracy: 91.80526315789473 %\nIteration: 30 Training Accuracy: 91.84210526315789 %\nIteration: 40 Training Accuracy: 91.86315789473684 %\nIteration: 50 Training Accuracy: 91.89473684210526 %\nIteration: 60 Training Accuracy: 91.93684210526317 %\nIteration: 70 Training Accuracy: 91.96842105263158 %\nIteration: 80 Training Accuracy: 91.99473684210527 %\nIteration: 90 Training Accuracy: 92.04473684210527 %\nIteration: 100 Training Accuracy: 92.07105263157894 %\nIteration: 110 Training Accuracy: 92.09736842105262 %\nIteration: 120 Training Accuracy: 92.12894736842105 %\nIteration: 130 Training Accuracy: 92.14473684210527 %\nIteration: 140 Training Accuracy: 92.17368421052632 %\nIteration: 150 Training Accuracy: 92.20789473684209 %\nIteration: 160 Training Accuracy: 92.23421052631579 %\nIteration: 170 Training Accuracy: 92.27368421052631 %\nIteration: 180 Training Accuracy: 92.30000000000001 %\nIteration: 190 Training Accuracy: 92.32105263157895 %\nIteration: 200 Training Accuracy: 92.34736842105264 %\nIteration: 210 Training Accuracy: 92.37894736842105 %\nIteration: 220 Training Accuracy: 92.39736842105263 %\nIteration: 230 Training Accuracy: 92.42894736842105 %\nIteration: 240 Training Accuracy: 92.4421052631579 %\nIteration: 250 Training Accuracy: 92.45526315789473 %\nIteration: 260 Training Accuracy: 92.47894736842105 %\nIteration: 270 Training Accuracy: 92.51052631578948 %\nIteration: 280 Training Accuracy: 92.54736842105264 %\nIteration: 290 Training Accuracy: 92.57368421052632 %\nIteration: 300 Training Accuracy: 92.58947368421052 %\nIteration: 310 Training Accuracy: 92.6078947368421 %\nIteration: 320 Training Accuracy: 92.64210526315789 %\nIteration: 330 Training Accuracy: 92.67105263157895 %\nIteration: 340 Training Accuracy: 92.7078947368421 %\nIteration: 350 Training Accuracy: 92.73421052631579 %\nIteration: 360 Training Accuracy: 92.75526315789475 %\nIteration: 370 Training Accuracy: 92.78684210526316 %\nIteration: 380 Training Accuracy: 92.8078947368421 %\nIteration: 390 Training Accuracy: 92.82368421052631 %\nIteration: 400 Training Accuracy: 92.84736842105264 %\nIteration: 410 Training Accuracy: 92.86315789473684 %\nIteration: 420 Training Accuracy: 92.86578947368422 %\nIteration: 430 Training Accuracy: 92.87631578947368 %\nIteration: 440 Training Accuracy: 92.9 %\nIteration: 450 Training Accuracy: 92.91842105263159 %\nIteration: 460 Training Accuracy: 92.94473684210526 %\nIteration: 470 Training Accuracy: 92.97105263157894 %\nIteration: 480 Training Accuracy: 93.0 %\nIteration: 490 Training Accuracy: 93.01842105263158 %\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"z1, a1, z2, a2, z3, a3, z4, a4 = forward_prop(w1, b1, w2, b2, w3, b3, w4, b4, x_test)\n\nval_predictions = np.argmax(a4, axis=0)\nval_accuracy = np.mean(val_predictions == y_test) * 100\n\nprint(\"Validation Accuracy:\", val_accuracy, \"%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T10:30:32.491219Z","iopub.execute_input":"2026-01-02T10:30:32.491524Z","iopub.status.idle":"2026-01-02T10:30:32.529970Z","shell.execute_reply.started":"2026-01-02T10:30:32.491500Z","shell.execute_reply":"2026-01-02T10:30:32.528330Z"}},"outputs":[{"name":"stdout","text":"Validation Accuracy: 92.65 %\n","output_type":"stream"}],"execution_count":31}]}